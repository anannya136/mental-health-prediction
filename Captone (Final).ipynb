{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxPQM5jfTeCv"
   },
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1677302,
     "status": "ok",
     "timestamp": 1748806148450,
     "user": {
      "displayName": "Fatema -Tuz- Zahura Anannya (221014124)",
      "userId": "13240839665614985408"
     },
     "user_tz": -360
    },
    "id": "GL6SS9qcoH9c",
    "outputId": "8634c23b-b088-48eb-d9b2-ec3d285c1b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing target: Stress_Level\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-bbcb27f111e2>:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Stress_Score\"] = df[stress_cols].sum(axis=1)\n",
      "<ipython-input-3-bbcb27f111e2>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Anxiety_Score\"] = df[anxiety_cols].sum(axis=1)\n",
      "<ipython-input-3-bbcb27f111e2>:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Depression_Score\"] = df[depression_cols].sum(axis=1)\n",
      "<ipython-input-3-bbcb27f111e2>:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Stress_Level\"] = df[\"Stress_Score\"].apply(lambda x: classify(x, 13, 26))\n",
      "<ipython-input-3-bbcb27f111e2>:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Anxiety_Level\"] = df[\"Anxiety_Score\"].apply(lambda x: classify(x, 7, 14))\n",
      "<ipython-input-3-bbcb27f111e2>:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Depression_Level\"] = df[\"Depression_Score\"].apply(lambda x: classify(x, 9, 18))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Random Forest Accuracy: 0.9841214699279215\n",
      "Stacking Classifier (with more models) | Accuracy: 0.9918\n",
      "Voting Ensemble | Accuracy: 0.9898\n",
      "Stacking Classifier | Cross-validated accuracy: 0.9917 ± 0.0041\n",
      "\n",
      "Processing target: Anxiety_Level\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best Random Forest Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Random Forest Accuracy: 0.9731046227321594\n",
      "Stacking Classifier (with more models) | Accuracy: 1.0000\n",
      "Voting Ensemble | Accuracy: 0.9971\n",
      "Stacking Classifier | Cross-validated accuracy: 0.9950 ± 0.0049\n",
      "\n",
      "Processing target: Depression_Level\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best Random Forest Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Random Forest Accuracy: 0.9599056603773585\n",
      "Stacking Classifier (with more models) | Accuracy: 0.9969\n",
      "Voting Ensemble | Accuracy: 0.9937\n",
      "Stacking Classifier | Cross-validated accuracy: 0.9870 ± 0.0060\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    ExtraTreesClassifier, StackingClassifier, VotingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "df = pd.read_csv(\"/content/Raw Dataset.csv\")\n",
    "df.columns = [col.split(\". \", 1)[-1].strip() for col in df.columns]\n",
    "\n",
    "stress_cols = df.columns[7:17]\n",
    "anxiety_cols = df.columns[17:24]\n",
    "depression_cols = df.columns[24:33]\n",
    "selected_cols = list(stress_cols) + list(anxiety_cols) + list(depression_cols)\n",
    "\n",
    "def convert_response(resp):\n",
    "    mapping = {\n",
    "        \"0 - Never\": 0, \"1 - Almost Never\": 1, \"2 - Sometimes\": 2,\n",
    "        \"3 - Fairly Often\": 3, \"4 - Very Often\": 4,\n",
    "        \"0 - Not at all\": 0, \"1 - Several days\": 1,\n",
    "        \"2 - More than half the days\": 2, \"3 - Nearly every day\": 3\n",
    "    }\n",
    "    return mapping.get(resp, np.nan)\n",
    "\n",
    "for col in selected_cols:\n",
    "    df[col] = df[col].apply(convert_response)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df[selected_cols] = imputer.fit_transform(df[selected_cols])\n",
    "\n",
    "def remove_outliers(df, cols):\n",
    "    Q1 = df[cols].quantile(0.25)\n",
    "    Q3 = df[cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[~((df[cols] < (Q1 - 1.5 * IQR)) | (df[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "df = remove_outliers(df, selected_cols)\n",
    "\n",
    "df[\"Stress_Score\"] = df[stress_cols].sum(axis=1)\n",
    "df[\"Anxiety_Score\"] = df[anxiety_cols].sum(axis=1)\n",
    "df[\"Depression_Score\"] = df[depression_cols].sum(axis=1)\n",
    "\n",
    "def classify(score, mild, moderate):\n",
    "    if score <= mild: return \"Low\"\n",
    "    elif score <= moderate: return \"Moderate\"\n",
    "    else: return \"Severe\"\n",
    "\n",
    "df[\"Stress_Level\"] = df[\"Stress_Score\"].apply(lambda x: classify(x, 13, 26))\n",
    "df[\"Anxiety_Level\"] = df[\"Anxiety_Score\"].apply(lambda x: classify(x, 7, 14))\n",
    "df[\"Depression_Level\"] = df[\"Depression_Score\"].apply(lambda x: classify(x, 9, 18))\n",
    "\n",
    "X = df[selected_cols]\n",
    "y = df[[\"Stress_Level\", \"Anxiety_Level\", \"Depression_Level\"]]\n",
    "\n",
    "os.makedirs(\"models/cv_models\", exist_ok=True)\n",
    "\n",
    "models = [\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"SVM\", SVC(probability=True, random_state=42)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n",
    "    (\"AdaBoost\", AdaBoostClassifier(random_state=42)),\n",
    "    (\"Naive Bayes\", GaussianNB()),\n",
    "    (\"Extra Trees\", ExtraTreesClassifier(random_state=42)),\n",
    "    (\"QDA\", QuadraticDiscriminantAnalysis()),\n",
    "    (\"LDA\", LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')),\n",
    "    (\"Ridge Classifier\", RidgeClassifier(alpha=1))\n",
    "]\n",
    "\n",
    "# Stratified K-Fold Cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "label_encoders = {label: LabelEncoder().fit(y[label]) for label in y.columns}\n",
    "\n",
    "# Loop through each label (target)\n",
    "for label in y.columns:\n",
    "    print(f\"\\nProcessing target: {label}\")\n",
    "\n",
    "    le = label_encoders[label]\n",
    "    y_encoded = le.transform(y[label])\n",
    "\n",
    "    selector = SelectKBest(f_classif, k=15)\n",
    "    X_selected = selector.fit_transform(X, y_encoded)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # SMOTE + ENN Resampling (via Pipeline)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    enn = EditedNearestNeighbours(n_neighbors=3)\n",
    "    resampling_pipeline = Pipeline(steps=[('smote', smote), ('enn', enn)])\n",
    "\n",
    "    X_resampled, y_resampled = resampling_pipeline.fit_resample(X_pca, y_encoded)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    "    )\n",
    "\n",
    "    # Hyperparameter tuning for Random Forest\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    print(f\"Best Random Forest Hyperparameters: {grid_rf.best_params_}\")\n",
    "    print(f\"Best Random Forest Accuracy: {grid_rf.best_score_}\")\n",
    "\n",
    "    # stacking classifier\n",
    "    base_learners = [\n",
    "        ('rf', RandomForestClassifier(n_estimators=200, random_state=42)),\n",
    "        ('svc', SVC(probability=True, random_state=42)),\n",
    "        ('mlp', MLPClassifier(hidden_layer_sizes=(256, 128, 64), activation='relu', solver='adam',\n",
    "                   alpha=0.0001, max_iter=500, learning_rate_init=0.001, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(random_state=42)),\n",
    "        ('ada', AdaBoostClassifier(random_state=42))\n",
    "    ]\n",
    "    meta_learner = LogisticRegression()\n",
    "    stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner)\n",
    "\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    stacking_acc = stacking_clf.score(X_val, y_val)\n",
    "    print(f\"Stacking Classifier (with more models) | Accuracy: {stacking_acc:.4f}\")\n",
    "    joblib.dump(stacking_clf, f\"models/cv_models/{label}_StackingClassifier.pkl\")\n",
    "\n",
    "    # Voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('svc', SVC(probability=True, random_state=42)),\n",
    "        ('mlp', MLPClassifier(hidden_layer_sizes=(256, 128, 64), activation='relu', solver='adam',\n",
    "                   alpha=0.0001, max_iter=500, learning_rate_init=0.001, random_state=42))\n",
    "    ], voting='soft')\n",
    "\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    ensemble_acc = ensemble.score(X_val, y_val)\n",
    "    print(f\"Voting Ensemble | Accuracy: {ensemble_acc:.4f}\")\n",
    "    joblib.dump(ensemble, f\"models/cv_models/{label}_VotingEnsemble.pkl\")\n",
    "\n",
    "    # Cross-validation with Repeated Stratified K-Fold\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    scores = cross_val_score(stacking_clf, X_resampled, y_resampled, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "    print(f\"Stacking Classifier | Cross-validated accuracy: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1zfNbxr6-ifMhSUwmOkDN1flKoeAr1rw-",
     "timestamp": 1748804177367
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
